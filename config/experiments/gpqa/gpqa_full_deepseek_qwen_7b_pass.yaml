# Experiment configuration for Qwen 32B
experiment_name: "gpqa_full_deepseek_qwen_7b_pass"
results_dir: "./results/gpqa_full_deepseek_qwen_7b_pass"
data_path: "./data/gpqa_diamond_mc.csv"
save_intermediate: true
experiment_type: "pass_k"

pass_k_iterations: 2

# Dashboard configuration
dashboard_port: 8080

# Model configuration
reasoning_model: "accounts/vivek-vajipey-84a360/deployedModels/deepseek-r1-distill-qwen-7b-bad1b741"
reasoning_model_provider: "fireworks"

# Generation parameters
max_tokens: 8192  # Maximum tokens per request (Fireworks limit for DeepSeek Qwen models)
temperature: 0.6
top_p: 0.95
top_k: 40
presence_penalty: 0.0
frequency_penalty: 0.0

# Continuation parameters (for Fireworks API)
enable_continuation: true  # Whether to automatically continue generation when token limit is reached
max_total_tokens: 131072  # Total token limit across all continuations
max_continuations: 16   # Maximum number of continuation attempts

answer_extractor: "gpqa_mc"

# Prompt configurations
prompts:
  reasoning: "gpqa_mc"  # This references the version in config/prompts/reasoning.yaml