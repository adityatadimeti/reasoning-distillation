# Experiment configuration
experiment_name: "test_aime_wrong"
results_dir: "./results/test_aime_wrong"
data_path: "./data/wrong_one_deepseek_aime_2024.csv"
save_intermediate: true

# Dashboard configuration
dashboard_port: 8080

# Model configuration
# reasoning_model: "accounts/fireworks/models/qwq-32b"
reasoning_model: "accounts/fireworks/models/deepseek-r1"
# summarizer_type: "self"
summarizer_type: "external"
summarizer_model: "accounts/fireworks/models/deepseek-v3"


# Generation parameters
<<<<<<< HEAD:config/experiments/test_aime_wrong.yaml
max_tokens: 32768
temperature: 0.6
top_p: 0.95
=======
max_tokens: 50000
temperature: 0.7
top_p: 1.0
>>>>>>> main:config/experiments/wrong_test.yaml
top_k: 40
presence_penalty: 0.0
frequency_penalty: 0.0

# Iteration parameters
max_iterations: 2  # This will do initial (0) plus one more iteration (1)
continue_after_correct: false  # Continue to iteration 1 even if iteration 0 is correct

# Summarization parameters
enable_summarization: true
<<<<<<< HEAD:config/experiments/test_aime_wrong.yaml
summary_max_tokens: 32768
summary_temperature: 0.6
summary_top_p: 0.95
=======
summary_max_tokens: 10000
summary_temperature: 0.7
summary_top_p: 1.0
>>>>>>> main:config/experiments/wrong_test.yaml
summary_top_k: 40
summary_presence_penalty: 0.0
summary_frequency_penalty: 0.0

# Prompt configurations
prompts:
  reasoning: "aime"  # This references the version in config/prompts/reasoning.yaml
<<<<<<< HEAD:config/experiments/test_aime_wrong.yaml
  summarize: "pure_summarization"  # This references the version in config/prompts/summarize.yaml
=======
  summarize: ""  # This references the version in config/prompts/summarize.yaml
>>>>>>> main:config/experiments/wrong_test.yaml
  improved: "aime" # This references the version in config/prompts/improved.yaml