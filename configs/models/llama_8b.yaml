# Configuration for DeepSeek R1 Distill Llama 8B

reasoning_model:
  name: deepseek-r1-distill-llama-8b
  model_id: accounts/fireworks/models/deepseek-r1-distill-llama-8b
  api_type: fireworks
  api_base: https://api.fireworks.ai/inference/v1
  # API key should be in environment variable FIREWORKS_API_KEY
  
  # Model parameters
  max_tokens: 2000
  temperature: 0.7
  top_p: 1.0
  top_k: 40
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # API settings
  timeout: 30  # API timeout in seconds
  retries: 3   # Number of retries for API calls
  retry_delay: 2  # Delay between retries in seconds

# Summarization model configuration (self-summarization by default)
summarization_model:
  name: deepseek-r1-distill-llama-8b
  model_id: accounts/fireworks/models/deepseek-r1-distill-llama-8b
  api_type: fireworks
  api_base: https://api.fireworks.ai/inference/v1
  
  # Model parameters - lower temperature for more focused summaries
  max_tokens: 1000
  temperature: 0.5
  top_p: 1.0
  top_k: 40
  frequency_penalty: 0.0
  presence_penalty: 0.0

# Reasoning settings
reasoning:
  think_tag: true
  max_extensions: 8  # Reasonable number of extensions for this model
  target_token_count: 2000