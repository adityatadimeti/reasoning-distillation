# Configuration for Fireworks AI distilled models

# DeepSeek R1 Distill Qwen 7B
reasoning_model:
  name: deepseek-r1-distill-qwen-7b
  model_id: accounts/fireworks/models/deepseek-r1-distill-qwen-7b
  api_type: fireworks
  api_base: https://api.fireworks.ai/inference/v1
  # API key should be in environment variable FIREWORKS_API_KEY
  
  # Model parameters
  max_tokens: 2000
  temperature: 0.7
  top_p: 1.0
  top_k: 40
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # API settings
  timeout: 30  # API timeout in seconds
  retries: 3   # Number of retries for API calls
  retry_delay: 2  # Delay between retries in seconds

# Summarization model configuration (using the original DeepSeek R1 for summarization)
summarization_model:
  name: deepseek-r1
  model_id: accounts/fireworks/models/deepseek-r1
  api_type: fireworks
  api_base: https://api.fireworks.ai/inference/v1
  
  # Model parameters - lower temperature for more focused summaries
  max_tokens: 1000
  temperature: 0.5
  top_p: 1.0
  top_k: 40
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # API settings
  timeout: 30
  retries: 3
  retry_delay: 2

# Reasoning settings
reasoning:
  think_tag: true   # Whether to use <think> tags
  max_extensions: 10  # Maximum number of reasoning extensions
  target_token_count: 2000  # Target token count for extensive reasoning
  
  # Continuation phrases for extending reasoning
  continuation_phrases:
    - "Let me think more about this."
    - "Actually, I should reconsider my approach."
    - "Let me analyze this further."
    - "Let me double-check this calculation."
    - "I need to think about this from another angle."
    - "Let me explore an alternative solution method."
    - "I should verify these results with another approach."
    - "Let me ensure the reasoning so far is correct."
    - "Let me consider if there are any edge cases."
    - "I'll try a different way to solve this problem."