{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "fireworks_key = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train_df = pd.read_parquet(splits['train'])\n",
    "test_df = pd.read_parquet(splits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_text = test_df['question'].iloc[0]\n",
    "q1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [01:20<46:50, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 3: 2 validation errors for QAResult\n",
      "question\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [13:00<26:05, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 41: 2 validation errors for QAResult\n",
      "question\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [27:18<06:01, 25.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 86: 2 validation errors for QAResult\n",
      "question\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [30:09<02:34, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 94: 2 validation errors for QAResult\n",
      "question\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [32:40<00:00, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 100: 2 validation errors for QAResult\n",
      "question\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "answer\n",
      "  Field required [type=missing, input_value={}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "Successfully saved processed data to parquet file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Define the output schema using Pydantic\n",
    "class QAResult(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "def process_questions(test_df, num_questions=100, output_file=\"reasoning_traces.txt\"):\n",
    "    # Initialize the Fireworks client\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    "        api_key=os.getenv(\"FIREWORKS_API_KEY\"),\n",
    "    )\n",
    "    \n",
    "    # Create new columns for reasoning and answers\n",
    "    test_df['reasoning_trace'] = ''\n",
    "    test_df['model_answer'] = ''\n",
    "    \n",
    "    # Open file for logging\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Process the specified number of questions\n",
    "        for idx in tqdm(range(min(num_questions, len(test_df)))):\n",
    "            try:\n",
    "                question = test_df['question'].iloc[idx]\n",
    "                \n",
    "                # Log the question\n",
    "                f.write(f\"\\nQuestion {idx + 1}:\\n{question}\\n\")\n",
    "                f.write(\"-\" * 80 + \"\\n\")\n",
    "                \n",
    "                # Construct the messages payload\n",
    "                messages = [{\"role\": \"user\", \"content\": question}]\n",
    "                \n",
    "                # Make the API call to the model\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"accounts/fireworks/models/deepseek-r1\",\n",
    "                    messages=messages,\n",
    "                    response_format={\"type\": \"json_object\", \"schema\": QAResult.model_json_schema()},\n",
    "                    max_tokens=3000,\n",
    "                )\n",
    "                \n",
    "                # Extract the content of the response\n",
    "                response_content = response.choices[0].message.content\n",
    "                \n",
    "                # Extract the reasoning part\n",
    "                reasoning_match = re.search(r\"<think>(.*?)</think>\", response_content, re.DOTALL)\n",
    "                reasoning = reasoning_match.group(1).strip() if reasoning_match else \"No reasoning provided.\"\n",
    "                \n",
    "                # Extract the JSON part\n",
    "                json_match = re.search(r\"</think>\\s*(\\{.*\\})\", response_content, re.DOTALL)\n",
    "                json_str = json_match.group(1).strip() if json_match else \"{}\"\n",
    "                \n",
    "                # Parse the JSON string using model_validate_json\n",
    "                qa_result = QAResult.model_validate_json(json_str)\n",
    "                \n",
    "                # Store in DataFrame\n",
    "                test_df.at[idx, 'reasoning_trace'] = reasoning\n",
    "                test_df.at[idx, 'model_answer'] = qa_result.answer\n",
    "                \n",
    "                # Log to file\n",
    "                f.write(\"Reasoning:\\n\")\n",
    "                f.write(reasoning + \"\\n\")\n",
    "                f.write(\"\\nQA Result:\\n\")\n",
    "                f.write(qa_result.model_dump_json(indent=4) + \"\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error processing question {idx + 1}: {str(e)}\"\n",
    "                print(error_msg)\n",
    "                f.write(f\"\\nERROR: {error_msg}\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\")\n",
    "                continue\n",
    "    \n",
    "    # Try to save the DataFrame\n",
    "    try:\n",
    "        test_df.to_parquet('processed_test_data.parquet')\n",
    "        print(\"Successfully saved processed data to parquet file\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving DataFrame: {str(e)}\")\n",
    "        print(\"Results are still available in the text file\")\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "# Run the processing\n",
    "processed_df = process_questions(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "processed_df.to_parquet('data/processed_test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning-distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
